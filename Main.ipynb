{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import ast\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_probs_of_vertices(dirname):\n",
    "    with open(dirname + \"Dependency.txt\") as f:\n",
    "        data = f.read()\n",
    "\n",
    "    dependencies = ast.literal_eval(data)\n",
    "    vertices_probs = {}\n",
    "    for vertex in dependencies:\n",
    "        dependent_vertices = dependencies[vertex]\n",
    "        vertices_probs[vertex] = {}\n",
    "        if (len(dependent_vertices) == 0):\n",
    "            Vertex_Probs = pd.read_csv(dirname + vertex + \"_Probs.csv\").set_index(vertex)\n",
    "            for i in list(Vertex_Probs.index):\n",
    "                vertices_probs[vertex][i] = Vertex_Probs[\"Probability\"][i]\n",
    "        elif (len(dependent_vertices) == 1):\n",
    "            Dependent_Vertex = dependent_vertices[0]\n",
    "            Current_Probs = pd.read_csv(dirname + vertex + \"_\" + Dependent_Vertex + \"_Probs.csv\")\n",
    "            if (Current_Probs[Dependent_Vertex].values.dtype == bool):\n",
    "                Current_Probs[Dependent_Vertex] = list(map(str, Current_Probs[Dependent_Vertex]))\n",
    "            Current_Probs.set_index(Dependent_Vertex, inplace=True)\n",
    "            Target_States = list(Current_Probs.columns)\n",
    "            Dependent_States = list(vertices_probs[Dependent_Vertex].keys())\n",
    "            for Target_State in Target_States:\n",
    "                vertices_probs[vertex][Target_State] = 0\n",
    "                for Dependent_State in Dependent_States:\n",
    "                    vertices_probs[vertex][Target_State] += Current_Probs[Target_State][Dependent_State] * vertices_probs[Dependent_Vertex][Dependent_State]\n",
    "        elif (len(dependent_vertices) > 1):\n",
    "            Current_Probs = pd.read_csv(dirname + vertex + \"_\" + \"_\".join(dependent_vertices) + \"_Probs.csv\")\n",
    "            for col_name in dependent_vertices:\n",
    "                if (Current_Probs[col_name].values.dtype == bool):\n",
    "                    Current_Probs[col_name] = list(map(str, Current_Probs[col_name]))\n",
    "            Current_Probs.set_index(dependent_vertices, inplace=True)\n",
    "            Indices = list(Current_Probs.index)\n",
    "            Target_States = list(Current_Probs.columns)\n",
    "            for Target_State in Target_States:\n",
    "                vertices_probs[vertex][Target_State] = 0\n",
    "                for Index in Indices:\n",
    "                    Marg_Probs = []\n",
    "                    for (dep_ver,dep_ver_state) in list(zip(dependent_vertices,Index)):\n",
    "                        Marg_Probs.append(vertices_probs[dep_ver][dep_ver_state])\n",
    "                    vertices_probs[vertex][Target_State] += np.prod(Marg_Probs) * Current_Probs[Target_State][Index]\n",
    "    return vertices_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_joint_probability_of_BN(dirname):\n",
    "    with open(dirname + \"Dependency.txt\") as f:\n",
    "        data = f.read()\n",
    "\n",
    "    dependencies = ast.literal_eval(data)\n",
    "    vertices = list(dependencies.keys())\n",
    "    vertices_all_states = []\n",
    "    for vertex in vertices:\n",
    "        vertex_states = pd.read_csv(dirname + vertex + \"_States.csv\")\n",
    "        vertex_states = list(vertex_states[vertex].values)\n",
    "        vertex_states = list(map(str, vertex_states))\n",
    "        vertices_all_states.append(vertex_states)\n",
    "    vertices_all_states = list(itertools.product(*vertices_all_states))\n",
    "    Table = pd.DataFrame(data=vertices_all_states, columns=vertices)\n",
    "    Table[\"Probability\"] = 1\n",
    "    for i in range(len(Table)):\n",
    "        Vertices_States_Set = list(zip(vertices,list(Table[vertices].iloc[i].values)))\n",
    "        for (Vertex,Vertex_state) in Vertices_States_Set:\n",
    "            Dependent_Vertices = dependencies[Vertex]\n",
    "            if (len(Dependent_Vertices) == 0):\n",
    "                Probs = pd.read_csv(dirname + Vertex + \"_Probs.csv\").set_index(Vertex)\n",
    "                Table[\"Probability\"].iloc[i] *= Probs[\"Probability\"][Vertex_state]\n",
    "            elif (len(Dependent_Vertices) == 1):\n",
    "                Dependent_Vertex = Dependent_Vertices[0]\n",
    "                Dependent_Vertex_State = Table[Dependent_Vertex].iloc[i]\n",
    "                Probs = pd.read_csv(dirname + Vertex + \"_\" + Dependent_Vertex + \"_Probs.csv\")\n",
    "                if (Probs[Dependent_Vertex].values.dtype == bool):\n",
    "                    Probs[Dependent_Vertex] = list(map(str, Probs[Dependent_Vertex]))\n",
    "                Probs.set_index(Dependent_Vertex, inplace=True)\n",
    "                Table[\"Probability\"].iloc[i] *= Probs[Vertex_state][Dependent_Vertex_State]\n",
    "            elif (len(Dependent_Vertices) > 1):\n",
    "                Dependent_Vertices_State = Table[Dependent_Vertices].iloc[i]\n",
    "                Probs = pd.read_csv(dirname + Vertex + \"_\" + \"_\".join(Dependent_Vertices) + \"_Probs.csv\")\n",
    "                for col_name in Dependent_Vertices:\n",
    "                    if (Probs[col_name].values.dtype == bool):\n",
    "                        Probs[col_name] = list(map(str, Probs[col_name]))\n",
    "                Probs.set_index(Dependent_Vertices, inplace=True)\n",
    "                Table[\"Probability\"].iloc[i] *= Probs.loc[tuple(Dependent_Vertices_State), Vertex_state]\n",
    "    Table.index = range(1,len(Table) + 1)\n",
    "    Table.index.name = \"Observation\"\n",
    "    Table.to_csv(dirname[:-1] +\"_Results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Animal': {'Monkey': 0.2,\n",
       "  'Penguin': 0.2,\n",
       "  'Platypus': 0.2,\n",
       "  'Robin': 0.2,\n",
       "  'Turtle': 0.2},\n",
       " 'Environment': {'Air': 0.1, 'Land': 0.5, 'Water': 0.4},\n",
       " 'HasShell': {'True': 0.2, 'False': 0.8},\n",
       " 'BearsYoungAs': {'Live': 0.2, 'Eggs': 0.8},\n",
       " 'Class': {'Bird': 0.4, 'Mammal': 0.4, 'Reptile': 0.2},\n",
       " 'WarmBlooded': {'True': 0.8, 'False': 0.2},\n",
       " 'BodyCovering': {'Fur': 0.4, 'Feathers': 0.4, 'Scales': 0.2}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_probs_of_vertices(\"Animal/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_joint_probability_of_BN(\"Animal/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'VisitAsia': {'Visit': 0.01, 'NoVisit': 0.99},\n",
       " 'Smoking': {'Smoking': 0.5, 'NoSmoking': 0.5},\n",
       " 'Tuberculosis': {'Present': 0.010400000000000001,\n",
       "  'Absent': 0.9895999999999999},\n",
       " 'LungCancer': {'Present': 0.055, 'Absent': 0.9450000000000001},\n",
       " 'Tb_or_Ca': {'True': 0.064828, 'False': 0.935172},\n",
       " 'XRay': {'Abnormal': 0.11029004, 'Normal': 0.8897099599999999},\n",
       " 'Bronchitis': {'Present': 0.44999999999999996, 'Absent': 0.55},\n",
       " 'Dyspnea': {'True': 0.4393105, 'False': 0.5606895000000001}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_probs_of_vertices(\"Asia/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  [['Visit', 'NoVisit'], ['Smoking', 'NoSmoking'], ['Present', 'Absent'], ['Present', 'Absent'], ['True', 'False'], ['Abnormal', 'Normal'], ['Present', 'Absent'], ['True', 'False']]\n"
     ]
    }
   ],
   "source": [
    "calculate_joint_probability_of_BN(\"Asia/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
